{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For automatically reload import package\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# Set Huggging Face Cache dir\n",
    "# import os\n",
    "# cache_dir = '/lustre/umt3/user/manyuan/CourseWork/huggingface'\n",
    "# os.environ['HF_HOME'] = cache_dir\n",
    "\n",
    "# External library\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Local library\n",
    "from dataset import DataSet\n",
    "import transformer as tfr\n",
    "import seq2seq as s2s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d520fd5c",
   "metadata": {},
   "source": [
    "# Prepare Translation DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328f47bc",
   "metadata": {},
   "source": [
    "## (1) Tatoeba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-current",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file and create dataset\n",
    "datafile = './data/cmn.txt'\n",
    "data = DataSet(max_length=128, source='en', target='zh')\n",
    "data.read_file(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b881c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample, sample_dec = data.tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc700d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check specific sample at specific index\n",
    "sample_id = 0\n",
    "print(sample['input_ids'][sample_id])\n",
    "print(sample['labels'][sample_id])\n",
    "print(sample_dec[sample_id])\n",
    "print(data.tokenizer.decode(sample['labels'][sample_id], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803c4e9c",
   "metadata": {},
   "source": [
    "## (2) Ted talks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d4e6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ted = DataSet(max_length=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b8cdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ted.read_xml('./data/IWSLT17.TED.tst2017.en-fr.en.xml', './data/IWSLT17.TED.tst2017.fr-en.fr.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69610880",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ted, sample_ted_dec = data_ted.tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48ac298",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_ted['input_ids'][0])\n",
    "print(sample_ted['labels'][0])\n",
    "print(sample_ted_dec[0])\n",
    "print(data_ted.tokenizer.decode(sample_ted['labels'][0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc02ceb",
   "metadata": {},
   "source": [
    "So now we can treat both dataset in the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f309b1a-40d9-4db8-9a06-21bbfc9958da",
   "metadata": {},
   "source": [
    "## Prepare Dataloader for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68f3224",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors = list()\n",
    "for i in tqdm(range(len(sample_dec))):\n",
    "    input_ids  = sample['input_ids'][i]\n",
    "    valid_lens = sample['attention_mask'][i].sum()\n",
    "    labels     = sample['labels'][i]\n",
    "    dec_inputs = sample_dec[i]\n",
    "# for i in tqdm(range(len(sample_ted_dec))):\n",
    "#     input_ids  = sample_ted['input_ids'][i]\n",
    "#     valid_lens = sample_ted['attention_mask'][i].sum()\n",
    "#     labels     = sample_ted['labels'][i]\n",
    "#     dec_inputs = sample_ted_dec[i]\n",
    "    tensors.append((input_ids, dec_inputs, valid_lens, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc9efbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(tensors, batch_size=128, shuffle=True)\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    enc_inputs, dec_inputs, valid_lens, labels = batch\n",
    "    print(enc_inputs.shape)\n",
    "    print(dec_inputs.shape)\n",
    "    print(valid_lens.shape)\n",
    "    print(labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89800b5",
   "metadata": {},
   "source": [
    "# Create NMT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-rebecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transformer Seq2Seq model\n",
    "# input parameters of encoder and decoder\n",
    "# (vocab_size, num_hiddens, ffn_num_hiddens, num_heads, num_blks, dropout, use_bias=False)\n",
    "# vocab_size  = data_ted.vocab_size\n",
    "vocab_size  = data.vocab_size + 1 # add a bos token\n",
    "num_hiddens = 256\n",
    "ffn_hiddens = 64\n",
    "num_heads   = 4\n",
    "num_blks    = 2\n",
    "dropout     = 0.2\n",
    "\n",
    "# Use transformer encoder/decoder. Can also use GRU encoder/decoder\n",
    "encoder = tfr.TransformerEncoder(vocab_size, num_hiddens, ffn_hiddens, num_heads, num_blks, dropout)\n",
    "decoder = tfr.TransformerDecoder(vocab_size, num_hiddens, ffn_hiddens, num_heads, num_blks, dropout)\n",
    "\n",
    "# Seq2Seq model\n",
    "padding_index = data.tokenizer.pad_token_id\n",
    "# padding_index = data_ted.tokenizer.pad_token_id\n",
    "lr = 1e-3\n",
    "\n",
    "model = s2s.Seq2Seq(encoder, decoder, padding_index, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29b8fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create GRU Seq2Seq model\n",
    "# vocab_size  = data_ted.vocab_size\n",
    "vocab_size  = data.vocab_size + 1 # add a <bos> special token\n",
    "embed_size = 256\n",
    "num_hiddens = 256\n",
    "num_layers = 2\n",
    "dropout = 0.2\n",
    "\n",
    "encoder = s2s.Seq2SeqEncoder(vocab_size, embed_size, num_hiddens, num_layers, dropout)\n",
    "decoder = s2s.Seq2SeqDecoder(vocab_size, embed_size, num_hiddens, num_layers, dropout)\n",
    "\n",
    "# padding_index = data_ted.tokenizer.pad_token_id\n",
    "padding_index = data.tokenizer.pad_token_id\n",
    "lr = 1e-3\n",
    "\n",
    "model = s2s.Seq2Seq(encoder, decoder, padding_index, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e06cbe9",
   "metadata": {},
   "source": [
    "# Training our NMT models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba5e7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "print(device)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "# Use wandb to monitor the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad59024c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "losses = list()\n",
    "\n",
    "model.to(device)\n",
    "model.train()\n",
    "for epoch in trange(epochs):\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        a, b, c, d = batch\n",
    "        enc_inputs = a.to(device)\n",
    "        dec_inputs = b.to(device)\n",
    "        valid_lens = c.to(device)\n",
    "        labels     = d.to(device)\n",
    "        \n",
    "        Y_hat = model(enc_inputs, dec_inputs, valid_lens)\n",
    "        \n",
    "        loss = model.loss(Y_hat.transpose(1, 2), labels)\n",
    "        \n",
    "        model.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        model.optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8550cf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65320273",
   "metadata": {},
   "source": [
    "# Create a SMT (Statistical Machine Translation) model as baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3ecd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('swadesh')\n",
    "from nltk.corpus import swadesh\n",
    "en2fr = [ (i.lower(), j.lower()) for i, j in swadesh.entries(['en', 'fr'])]\n",
    "translation_dict = dict(en2fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e701ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence):\n",
    "    \"\"\"\n",
    "    Translate a sentence using the translation dictionary.\n",
    "    \n",
    "    Args:\n",
    "    sentence (str): Input sentence in English.\n",
    "    \n",
    "    Returns:\n",
    "    str: Translated sentence in French.\n",
    "    \"\"\"\n",
    "    # Tokenize the input sentence\n",
    "    tokens = sentence.lower().split()\n",
    "    \n",
    "    # Translate each token using the dictionary, if available\n",
    "    translated_tokens = [translation_dict.get(token, token) for token in tokens]\n",
    "    \n",
    "    # Join the translated tokens to form the translated sentence\n",
    "    translated_sentence = ' '.join(translated_tokens)\n",
    "    \n",
    "    return translated_sentence\n",
    "\n",
    "# Example usage\n",
    "english_sentence = \"far .\"\n",
    "french_translation = translate_sentence(english_sentence)\n",
    "print(\"English:\", english_sentence)\n",
    "print(\"French:\", french_translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f93fca5",
   "metadata": {},
   "source": [
    "# Evaluation of different models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4af434",
   "metadata": {},
   "source": [
    "## (1) BLEU and BERT Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bff850",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = 4\n",
    "test_dataloader = DataLoader(tensors[:512], batch_size=test_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f035b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "for batch in test_dataloader:\n",
    "    # Greedy decoding\n",
    "    # preds, _ = model.predict_step(batch, device, data.max_length)\n",
    "    # Beam search decoding\n",
    "    preds = model.beam_search(batch, device, 2, data.max_length)\n",
    "    srcs = [data.tokenizer.convert_ids_to_tokens(batch[0][i], skip_special_tokens=True) for i in range(test_batch_size)]\n",
    "    tgts = [data.tokenizer.convert_ids_to_tokens(batch[3][i], skip_special_tokens=True) for i in range(test_batch_size)]\n",
    "    \n",
    "    for src, tgt, p in zip(srcs, tgts, preds):\n",
    "        translation = []\n",
    "        for token in data.tokenizer.convert_ids_to_tokens(p):\n",
    "            if token == '</s>':\n",
    "                break\n",
    "            translation.append(token)\n",
    "        str_src = data.tokenizer.convert_tokens_to_string(src)\n",
    "        str_tgt = data.tokenizer.convert_tokens_to_string(tgt)\n",
    "        pred = data.tokenizer.convert_tokens_to_string(translation)\n",
    "        print(pred)\n",
    "\n",
    "        # BLEU Score\n",
    "        print(f'{str_src} => {str_tgt}, bleu, '\n",
    "              f'{s2s.bleu(translation, tgt, k=2):.3f}')\n",
    "        # BERT Score\n",
    "        print(f'{str_src} => {str_tgt}, bert score, '\n",
    "              f'{s2s.bert_score(pred, str_tgt, lang=\"zh\")[\"f1\"][0]:.3f}')\n",
    "        # SMT model\n",
    "        # print(f'{str_en} => {translate_sentence(str_en)}, bleu,'\n",
    "        #       f'{s2s.bleu(translate_sentence(str_en), fr, k=2):.3f}')\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de53f560",
   "metadata": {},
   "outputs": [],
   "source": [
    "fras = [5682, 21, 2137, 19, 6381, 21, 682, 291, 0,]\n",
    "engs = [631, 250, 0, 59513]\n",
    "print(data.tokenizer.convert_tokens_to_string(data.tokenizer.convert_ids_to_tokens(engs)))\n",
    "print(data.tokenizer.convert_ids_to_tokens(fras))\n",
    "print(data.tokenizer.decode(fras))\n",
    "print(data.tokenizer.convert_tokens_to_string(data.tokenizer.convert_ids_to_tokens(fras)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7767ba3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2s.bleu(\"a b c d e\", \"a b c e f\", k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bfeefa",
   "metadata": {},
   "source": [
    "## (2) chrF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af37e8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b3ea65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99470ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53898086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ee65af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9602684",
   "metadata": {},
   "source": [
    "## (3) Bert_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3641cda",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
