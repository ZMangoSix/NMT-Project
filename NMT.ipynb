{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "quality-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Local library\n",
    "from dataset import DataSet\n",
    "import transformer as tfr\n",
    "import seq2seq as s2s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d520fd5c",
   "metadata": {},
   "source": [
    "# Prepare Translation DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "humanitarian-current",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 229803\n"
     ]
    }
   ],
   "source": [
    "# Read file and create dataset\n",
    "data = DataSet()\n",
    "data.read_file('./data/fra.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc700d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  631,   250,     0, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "         59513, 59513, 59513, 59513, 59513, 59513],\n",
      "        [  631,   250,     0, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "         59513, 59513, 59513, 59513, 59513, 59513],\n",
      "        [  631,   250,     0, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "         59513, 59513, 59513, 59513, 59513, 59513]]), 'attention_mask': tensor([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([[  740,   291,     0, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "         59513, 59513, 59513, 59513, 59513, 59513],\n",
      "        [ 4714,   250,     0, 59513, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "         59513, 59513, 59513, 59513, 59513, 59513],\n",
      "        [   23,  2020,   291,     0, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "         59513, 59513, 59513, 59513, 59513, 59513]])}\n",
      "tensor([[    0,   740,   291,     0, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "         59513, 59513, 59513, 59513, 59513, 59513],\n",
      "        [    0,  4714,   250,     0, 59513, 59513, 59513, 59513, 59513, 59513,\n",
      "         59513, 59513, 59513, 59513, 59513, 59513],\n",
      "        [    0,    23,  2020,   291,     0, 59513, 59513, 59513, 59513, 59513,\n",
      "         59513, 59513, 59513, 59513, 59513, 59513]])\n"
     ]
    }
   ],
   "source": [
    "sample, dec_inputs = data.tokenize()\n",
    "print(sample)\n",
    "print(dec_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89800b5",
   "metadata": {},
   "source": [
    "# Create NMT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "horizontal-rebecca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/envs/torch2.0.1/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "# Create transformer Seq2Seq model\n",
    "# input parameters of encoder and decoder\n",
    "# (vocab_size, num_hiddens, ffn_num_hiddens, num_heads, num_blks, dropout, use_bias=False)\n",
    "vocab_size  = data.vocab_size\n",
    "num_hiddens = 32\n",
    "ffn_hiddens = 64\n",
    "num_heads   = 8\n",
    "num_blks    = 2\n",
    "dropout     = 0.2\n",
    "\n",
    "# Use transformer encoder/decoder. Can also use GRU encoder/decoder\n",
    "encoder = tfr.TransformerEncoder(vocab_size, num_hiddens, ffn_hiddens, num_heads, num_blks, dropout)\n",
    "decoder = tfr.TransformerDecoder(vocab_size, num_hiddens, ffn_hiddens, num_heads, num_blks, dropout)\n",
    "\n",
    "model = s2s.Seq2Seq(encoder, decoder, 0, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e06cbe9",
   "metadata": {},
   "source": [
    "# Training our NMT models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d138c082",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_inputs = sample['input_ids']\n",
    "valid_lens = sample['attention_mask'].sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad59024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model(enc_inputs, dec_inputs, valid_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8550cf08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 16, 59514])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f035b28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
